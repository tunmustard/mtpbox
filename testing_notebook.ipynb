{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program to illustrate the concept \n",
    "# of threading \n",
    "# importing the threading module \n",
    "import threading \n",
    "\n",
    "def print_cube(num): \n",
    "\t\"\"\" \n",
    "\tfunction to print cube of given num \n",
    "\t\"\"\"\n",
    "\tprint(\"Cube: %s\"%(num * num * num)) \n",
    "\n",
    "def print_square(num): \n",
    "\t\"\"\" \n",
    "\tfunction to print square of given num \n",
    "\t\"\"\"\n",
    "\tprint(\"Square: %s\"%(num * num)) \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Square: 100\n",
      "Cube: 1000\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\": \n",
    "    # creating thread \n",
    "\tt1 = threading.Thread(target=print_square, args=(10,)) \n",
    "\tt2 = threading.Thread(target=print_cube, args=(10,)) \n",
    "\n",
    "\t# starting thread 1 \n",
    "\tt1.start() \n",
    "\t# starting thread 2 \n",
    "\tt2.start() \n",
    "\n",
    "\t# wait until thread 1 is completely executed \n",
    "\tt1.join() \n",
    "\t# wait until thread 2 is completely executed \n",
    "\tt2.join() \n",
    "\n",
    "\t# both threads completely executed \n",
    "\tprint(\"Done!\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Python program to illustrate the concept \n",
    "# of threading \n",
    "import threading \n",
    "import os \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID of process running main program: 13\n",
      "Main thread name: MainThread\n",
      "Task 1 assigned to thread: t1\n",
      "ID of process running task 1: 13\n",
      "Task 2 assigned to thread: t2\n",
      "ID of process running task 2: 13\n"
     ]
    }
   ],
   "source": [
    "def task1(): \n",
    "    print(\"Task 1 assigned to thread: {}\".format(threading.current_thread().name)) \n",
    "    print(\"ID of process running task 1: {}\".format(os.getpid())) \n",
    "\n",
    "def task2(): \n",
    "    print(\"Task 2 assigned to thread: {}\".format(threading.current_thread().name)) \n",
    "    print(\"ID of process running task 2: {}\".format(os.getpid())) \n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "  \n",
    "    # print ID of current process \n",
    "    print(\"ID of process running main program: {}\".format(os.getpid())) \n",
    "  \n",
    "    # print name of main thread \n",
    "    print(\"Main thread name: {}\".format(threading.main_thread().name)) \n",
    "  \n",
    "    # creating threads \n",
    "    t1 = threading.Thread(target=task1, name='t1') \n",
    "    t2 = threading.Thread(target=task2, name='t2')   \n",
    "  \n",
    "    # starting threads \n",
    "    t1.start() \n",
    "    t2.start() \n",
    "  \n",
    "    # wait until all threads finish \n",
    "    t1.join() \n",
    "    t2.join() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:05:42: Main    : before creating thread\n",
      "16:05:42: Main    : before running thread\n",
      "16:05:42: Thread 1: starting\n",
      "16:05:42: Main    : wait for the thread to finish\n",
      "16:05:44: Thread 1: finishing\n",
      "16:05:44: Main    : all done\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "import threading\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "def thread_function(name):\n",
    "\n",
    "    logging.info(\"Thread %s: starting\", name)\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "    logging.info(\"Thread %s: finishing\", name)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    format = \"%(asctime)s: %(message)s\"\n",
    "\n",
    "    logging.basicConfig(format=format, level=logging.INFO,\n",
    "\n",
    "                        datefmt=\"%H:%M:%S\")\n",
    "\n",
    "\n",
    "    logging.info(\"Main    : before creating thread\")\n",
    "\n",
    "    x = threading.Thread(target=thread_function, args=(1,),) # daemon=True\n",
    "\n",
    "    logging.info(\"Main    : before running thread\")\n",
    "\n",
    "    x.start()\n",
    "\n",
    "    logging.info(\"Main    : wait for the thread to finish\")\n",
    "\n",
    "    x.join()\n",
    "\n",
    "    logging.info(\"Main    : all done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:27:35: Thread 1 2: starting\n"
     ]
    }
   ],
   "source": [
    "name1 = \"1\"\n",
    "name2 = \"2\"\n",
    "logging.info(\"Thread %s %s: starting\", name1,name2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:08:54: Main    : create and start thread 0.\n",
      "18:08:54: Thread 0 0: starting\n",
      "18:08:54: Main    : create and start thread 1.\n",
      "18:08:54: Thread 1 1: starting\n",
      "18:08:54: Main    : create and start thread 2.\n",
      "18:08:54: Thread 2 2: starting\n",
      "18:08:54: Main    : before joining thread 0.\n",
      "18:08:56: Thread 0 0: finishing\n",
      "18:08:56: Main    : thread 0 done\n",
      "18:08:56: Main    : before joining thread 1.\n",
      "18:08:56: Thread 1 1: finishing\n",
      "18:08:56: Main    : thread 1 done\n",
      "18:08:56: Main    : before joining thread 2.\n",
      "18:08:56: Thread 2 2: finishing\n",
      "18:08:56: Main    : thread 2 done\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import threading\n",
    "import time\n",
    "\n",
    "def thread_function(name1,name2):\n",
    "    logging.info(\"Thread %s %s: starting\", name1,name2)\n",
    "    time.sleep(2)\n",
    "    logging.info(\"Thread %s %s: finishing\", name1,name2)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    format = \"%(asctime)s: %(message)s\"\n",
    "    logging.basicConfig(format=format, level=logging.INFO,\n",
    "                        datefmt=\"%H:%M:%S\")\n",
    "\n",
    "    threads = list()\n",
    "    for index in range(3):\n",
    "        logging.info(\"Main    : create and start thread %d.\", index)\n",
    "        x = threading.Thread(target=thread_function, args=(index,index))\n",
    "        threads.append(x)\n",
    "        x.start()\n",
    "\n",
    "    for index, thread in enumerate(threads):\n",
    "        logging.info(\"Main    : before joining thread %d.\", index)\n",
    "        thread.join()\n",
    "        logging.info(\"Main    : thread %d done\", index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:33:42: Thread 1 4: starting\n",
      "16:33:42: Thread 2 5: starting\n",
      "16:33:42: Thread 3 6: starting\n",
      "16:33:44: Thread 1 4: finishing\n",
      "16:33:44: Thread 2 5: finishing\n",
      "16:33:44: Thread 3 6: finishing\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "# [rest of code]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    format = \"%(asctime)s: %(message)s\"\n",
    "    logging.basicConfig(format=format, level=logging.INFO,\n",
    "                        datefmt=\"%H:%M:%S\")\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:\n",
    "        executor.map(thread_function, [1,2,3],[4,5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeDatabase:\n",
    "    def __init__(self):\n",
    "        self.value = 0\n",
    "\n",
    "    def update(self, name):\n",
    "        logging.info(\"Thread %s: starting update\", name)\n",
    "        local_copy = self.value\n",
    "        local_copy += 1\n",
    "        time.sleep(0.1)\n",
    "        self.value = local_copy\n",
    "        logging.info(\"Thread %s: finishing update\", name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:52:53: Testing update. Starting value is 0.\n",
      "16:52:53: Thread 0: starting update\n",
      "16:52:53: Thread 1: starting update\n",
      "16:52:53: Thread 0: finishing update\n",
      "16:52:53: Thread 1: finishing update\n",
      "16:52:53: Testing update. Ending value is 1.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    format = \"%(asctime)s: %(message)s\"\n",
    "    logging.basicConfig(format=format, level=logging.INFO,\n",
    "                        datefmt=\"%H:%M:%S\")\n",
    "\n",
    "    database = FakeDatabase()\n",
    "    logging.info(\"Testing update. Starting value is %d.\", database.value)\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
    "        for index in range(2):\n",
    "            executor.submit(database.update, index)\n",
    "    logging.info(\"Testing update. Ending value is %d.\", database.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeDatabase:\n",
    "    def __init__(self):\n",
    "        self.value = 0\n",
    "        self._lock = threading.Lock()\n",
    "\n",
    "    def locked_update(self, name):\n",
    "        logging.info(\"Thread %s: starting update\", name)\n",
    "        logging.debug(\"Thread %s about to lock\", name)\n",
    "        with self._lock:\n",
    "            logging.debug(\"Thread %s has lock\", name)\n",
    "            local_copy = self.value\n",
    "            local_copy += 1\n",
    "            time.sleep(0.1)\n",
    "            self.value = local_copy\n",
    "            logging.debug(\"Thread %s about to release lock\", name)\n",
    "        logging.debug(\"Thread %s after release\", name)\n",
    "        logging.info(\"Thread %s: finishing update\", name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:00:48: Testing update. Starting value is 0.\n",
      "17:00:48: Thread 0: starting update\n",
      "17:00:48: Thread 0 about to lock\n",
      "17:00:48: Thread 0 has lock\n",
      "17:00:48: Thread 1: starting update\n",
      "17:00:48: Thread 1 about to lock\n",
      "17:00:48: Thread 0 about to release lock\n",
      "17:00:48: Thread 0 after release\n",
      "17:00:48: Thread 0: finishing update\n",
      "17:00:48: Thread 1 has lock\n",
      "17:00:48: Thread 1 about to release lock\n",
      "17:00:48: Thread 1 after release\n",
      "17:00:48: Thread 1: finishing update\n",
      "17:00:48: Testing update. Ending value is 2.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    format = \"%(asctime)s: %(message)s\"\n",
    "    logging.basicConfig(format=format, level=logging.INFO,\n",
    "                        datefmt=\"%H:%M:%S\")\n",
    "    logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "    database = FakeDatabase()\n",
    "    logging.info(\"Testing update. Starting value is %d.\", database.value)\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
    "        for index in range(2):\n",
    "            executor.submit(database.locked_update, index)\n",
    "    logging.info(\"Testing update. Ending value is %d.\", database.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:41:25: Producer got message: 52\n",
      "17:41:25: Producer got message: 20\n",
      "17:41:25: Consumer storing message: 52\n",
      "17:41:25: Producer got message: 5\n",
      "17:41:25: Producer got message: 80\n",
      "17:41:25: Consumer storing message: 20\n",
      "17:41:25: Consumer storing message: 5\n",
      "17:41:25: Producer got message: 66\n",
      "17:41:25: Consumer storing message: 80\n",
      "17:41:25: Producer got message: 47\n",
      "17:41:25: Consumer storing message: 66\n",
      "17:41:25: Producer got message: 33\n",
      "17:41:25: Consumer storing message: 47\n",
      "17:41:25: Producer got message: 34\n",
      "17:41:25: Consumer storing message: 33\n",
      "17:41:25: Producer got message: 77\n",
      "17:41:25: Consumer storing message: 34\n",
      "17:41:25: Producer got message: 4\n",
      "17:41:25: Consumer storing message: 77\n",
      "17:41:25: Consumer storing message: 4\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "import logging\n",
    "import threading\n",
    "import time\n",
    "import concurrent.futures\n",
    "\n",
    "SENTINEL = object()\n",
    "\n",
    "def producer(pipeline):\n",
    "    \"\"\"Pretend we're getting a message from the network.\"\"\"\n",
    "    for index in range(10):\n",
    "        message = random.randint(1, 101)\n",
    "        logging.info(\"Producer got message: %s\", message)\n",
    "        pipeline.set_message(message, \"Producer\")\n",
    "\n",
    "    # Send a sentinel message to tell consumer we're done\n",
    "    pipeline.set_message(SENTINEL, \"Producer\")\n",
    "    \n",
    "def consumer(pipeline):\n",
    "    \"\"\"Pretend we're saving a number in the database.\"\"\"\n",
    "    message = 0\n",
    "    while message is not SENTINEL:\n",
    "        message = pipeline.get_message(\"Consumer\")\n",
    "        if message is not SENTINEL:\n",
    "            logging.info(\"Consumer storing message: %s\", message)\n",
    "            \n",
    "\n",
    "        \n",
    "class Pipeline:\n",
    "    \"\"\"\n",
    "    Class to allow a single element pipeline between producer and consumer.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.message = 0\n",
    "        self.producer_lock = threading.Lock()\n",
    "        self.consumer_lock = threading.Lock()\n",
    "        self.consumer_lock.acquire()\n",
    "\n",
    "    def get_message(self, name):\n",
    "        logging.debug(\"%s:about to acquire getlock\", name)\n",
    "        self.consumer_lock.acquire()\n",
    "        logging.debug(\"%s:have getlock\", name)\n",
    "        message = self.message\n",
    "        logging.debug(\"%s:about to release setlock\", name)\n",
    "        self.producer_lock.release()\n",
    "        logging.debug(\"%s:setlock released\", name)\n",
    "        return message\n",
    "\n",
    "    def set_message(self, message, name):\n",
    "        logging.debug(\"%s:about to acquire setlock\", name)\n",
    "        self.producer_lock.acquire()\n",
    "        logging.debug(\"%s:have setlock\", name)\n",
    "        self.message = message\n",
    "        logging.debug(\"%s:about to release getlock\", name)\n",
    "        self.consumer_lock.release()\n",
    "        logging.debug(\"%s:getlock released\", name)\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    format = \"%(asctime)s: %(message)s\"\n",
    "    logging.basicConfig(format=format, level=logging.INFO,\n",
    "                        datefmt=\"%H:%M:%S\")\n",
    "    logging.getLogger().setLevel(logging.INFO) #.DEBUG\n",
    "\n",
    "    pipeline = Pipeline()\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
    "        executor.submit(producer, pipeline)\n",
    "        executor.submit(consumer, pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:06:54: Producer got message: 96\n",
      "18:06:54: Producer got message: 100\n",
      "18:06:54: Producer got message: 10\n",
      "18:06:54: Producer got message: 75\n",
      "18:06:54: Consumer storing message: 96  (queue size=2)\n",
      "18:06:54: Producer got message: 39\n",
      "18:06:54: Producer got message: 80\n",
      "18:06:54: Producer got message: 43\n",
      "18:06:54: Consumer storing message: 100  (queue size=2)\n",
      "18:06:54: Producer got message: 35\n",
      "18:06:54: Consumer storing message: 10  (queue size=4)\n",
      "18:06:54: Producer got message: 39\n",
      "18:06:54: Consumer storing message: 75  (queue size=4)\n",
      "18:06:54: Producer got message: 30\n",
      "18:06:54: Consumer storing message: 39  (queue size=4)\n",
      "18:06:54: Producer got message: 69\n",
      "18:06:54: Consumer storing message: 80  (queue size=4)\n",
      "18:06:54: Producer got message: 1\n",
      "18:06:54: Consumer storing message: 43  (queue size=4)\n",
      "18:06:54: Producer got message: 28\n",
      "18:06:54: Consumer storing message: 35  (queue size=4)\n",
      "18:06:54: Producer got message: 69\n",
      "18:06:54: Consumer storing message: 39  (queue size=4)\n",
      "18:06:54: Producer got message: 67\n",
      "18:06:54: Consumer storing message: 30  (queue size=4)\n",
      "18:06:54: Producer got message: 5\n",
      "18:06:54: Consumer storing message: 69  (queue size=4)\n",
      "18:06:54: Producer got message: 83\n",
      "18:06:54: Consumer storing message: 1  (queue size=4)\n",
      "18:06:54: Producer got message: 46\n",
      "18:06:54: Consumer storing message: 28  (queue size=4)\n",
      "18:06:54: Producer got message: 45\n",
      "18:06:54: Consumer storing message: 69  (queue size=4)\n",
      "18:06:54: Producer got message: 53\n",
      "18:06:54: Consumer storing message: 67  (queue size=4)\n",
      "18:06:54: Producer got message: 52\n",
      "18:06:54: Consumer storing message: 5  (queue size=4)\n",
      "18:06:54: Producer got message: 97\n",
      "18:06:54: Consumer storing message: 83  (queue size=4)\n",
      "18:06:54: Producer got message: 71\n",
      "18:06:54: Consumer storing message: 46  (queue size=4)\n",
      "18:06:54: Consumer storing message: 45  (queue size=4)\n",
      "18:06:54: Producer got message: 78\n",
      "18:06:54: Consumer storing message: 53  (queue size=3)\n",
      "18:06:54: Producer got message: 89\n",
      "18:06:54: Consumer storing message: 52  (queue size=3)\n",
      "18:06:54: Producer got message: 87\n",
      "18:06:54: Producer got message: 6\n",
      "18:06:54: Consumer storing message: 97  (queue size=3)\n",
      "18:06:54: Consumer storing message: 71  (queue size=4)\n",
      "18:06:54: Producer got message: 16\n",
      "18:06:54: Producer got message: 4\n",
      "18:06:54: Consumer storing message: 78  (queue size=3)\n",
      "18:06:54: Consumer storing message: 89  (queue size=4)\n",
      "18:06:54: Producer got message: 7\n",
      "18:06:54: Producer got message: 2\n",
      "18:06:54: Consumer storing message: 87  (queue size=3)\n",
      "18:06:54: Consumer storing message: 6  (queue size=4)\n",
      "18:06:54: Producer got message: 33\n",
      "18:06:54: Main: about to set event\n",
      "18:06:54: Consumer storing message: 16  (queue size=3)\n",
      "18:06:54: Producer got message: 91\n",
      "18:06:54: Consumer storing message: 4  (queue size=3)\n",
      "18:06:54: Producer received EXIT event. Exiting\n",
      "18:06:54: Consumer storing message: 7  (queue size=3)\n",
      "18:06:54: Consumer storing message: 2  (queue size=2)\n",
      "18:06:54: Consumer storing message: 33  (queue size=1)\n",
      "18:06:54: Consumer storing message: 91  (queue size=0)\n",
      "18:06:54: Consumer received EXIT event. Exiting\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "import logging\n",
    "import threading\n",
    "import time\n",
    "import queue\n",
    "import concurrent.futures\n",
    "\n",
    "\n",
    "class Pipeline(queue.Queue):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super().__init__(maxsize=10)\n",
    "\n",
    "\n",
    "    def get_message(self, name):\n",
    "\n",
    "        logging.debug(\"%s:about to get from queue\", name)\n",
    "\n",
    "        value = self.get()\n",
    "\n",
    "        logging.debug(\"%s:got %d from queue\", name, value)\n",
    "\n",
    "        return value\n",
    "\n",
    "\n",
    "    def set_message(self, value, name):\n",
    "\n",
    "        logging.debug(\"%s:about to add %d to queue\", name, value)\n",
    "\n",
    "        self.put(value)\n",
    "\n",
    "        logging.debug(\"%s:added %d to queue\", name, value)\n",
    "\n",
    "        \n",
    "        \n",
    "def producer(pipeline, event):\n",
    "\n",
    "    \"\"\"Pretend we're getting a number from the network.\"\"\"\n",
    "\n",
    "    while not event.is_set():\n",
    "\n",
    "        message = random.randint(1, 101)\n",
    "\n",
    "        logging.info(\"Producer got message: %s\", message)\n",
    "\n",
    "        pipeline.set_message(message, \"Producer\")\n",
    "\n",
    "\n",
    "    logging.info(\"Producer received EXIT event. Exiting\")\n",
    "    \n",
    "    \n",
    "def consumer(pipeline, event):\n",
    "\n",
    "    \"\"\"Pretend we're saving a number in the database.\"\"\"\n",
    "\n",
    "    while not event.is_set() or not pipeline.empty():\n",
    "\n",
    "        message = pipeline.get_message(\"Consumer\")\n",
    "\n",
    "        logging.info(\n",
    "\n",
    "            \"Consumer storing message: %s  (queue size=%s)\",\n",
    "\n",
    "            message,\n",
    "\n",
    "            pipeline.qsize(),\n",
    "\n",
    "        )\n",
    "\n",
    "\n",
    "    logging.info(\"Consumer received EXIT event. Exiting\")\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    format = \"%(asctime)s: %(message)s\"\n",
    "\n",
    "    logging.basicConfig(format=format, level=logging.INFO,\n",
    "\n",
    "                        datefmt=\"%H:%M:%S\")\n",
    "\n",
    "    # logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "\n",
    "    pipeline = Pipeline()\n",
    "\n",
    "    event = threading.Event()\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
    "\n",
    "        executor.submit(producer, pipeline, event)\n",
    "\n",
    "        executor.submit(consumer, pipeline, event)\n",
    "\n",
    "\n",
    "        time.sleep(0.1)\n",
    "\n",
    "        logging.info(\"Main: about to set event\")\n",
    "\n",
    "        event.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:29:34: Producer got message: 53\n",
      "18:29:34: Producer got message: 85\n",
      "18:29:34: Producer got message: 22\n",
      "18:29:34: Producer got message: 64\n",
      "18:29:34: Producer got message: 86\n",
      "18:29:34: Producer got message: 60\n",
      "18:29:34: Producer got message: 94\n",
      "18:29:34: Producer got message: 76\n",
      "18:29:34: Consumer storing message: 53 (size=6)\n",
      "18:29:34: Main: about to set event\n",
      "18:29:34: Producer got message: 84\n",
      "18:29:34: Consumer storing message: 85 (size=6)\n",
      "18:29:34: Producer received event. Exiting\n",
      "18:29:34: Consumer storing message: 22 (size=6)\n",
      "18:29:34: Consumer storing message: 64 (size=5)\n",
      "18:29:34: Consumer storing message: 86 (size=4)\n",
      "18:29:34: Consumer storing message: 60 (size=3)\n",
      "18:29:34: Consumer storing message: 94 (size=2)\n",
      "18:29:34: Consumer storing message: 76 (size=1)\n",
      "18:29:34: Consumer storing message: 84 (size=0)\n",
      "18:29:34: Consumer received event. Exiting\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "import logging\n",
    "import queue\n",
    "import random\n",
    "import threading\n",
    "import time\n",
    "\n",
    "def producer(queue, event):\n",
    "    \"\"\"Pretend we're getting a number from the network.\"\"\"\n",
    "    while not event.is_set():\n",
    "        message = random.randint(1, 101)\n",
    "        logging.info(\"Producer got message: %s\", message)\n",
    "        queue.put(message)\n",
    "\n",
    "    logging.info(\"Producer received event. Exiting\")\n",
    "\n",
    "def consumer(queue, event):\n",
    "    \"\"\"Pretend we're saving a number in the database.\"\"\"\n",
    "    while not event.is_set() or not queue.empty():\n",
    "        message = queue.get()\n",
    "        logging.info(\n",
    "            \"Consumer storing message: %s (size=%d)\", message, queue.qsize()\n",
    "        )\n",
    "\n",
    "    logging.info(\"Consumer received event. Exiting\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    format = \"%(asctime)s: %(message)s\"\n",
    "    logging.basicConfig(format=format, level=logging.INFO,\n",
    "                        datefmt=\"%H:%M:%S\")\n",
    "\n",
    "    pipeline = queue.Queue(maxsize=10)\n",
    "    event = threading.Event()\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
    "        executor.submit(producer, pipeline, event)\n",
    "        executor.submit(consumer, pipeline, event)\n",
    "\n",
    "        time.sleep(2)\n",
    "        logging.info(\"Main: about to set event\")\n",
    "        event.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'asyncio' has no attribute 'run'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-831eb7593733>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0melapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{__file__} executed in {elapsed:0.2f} seconds.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'asyncio' has no attribute 'run'"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "async def count():\n",
    "    print(\"One\")\n",
    "    await asyncio.sleep(1)\n",
    "    print(\"Two\")\n",
    "\n",
    "async def main():\n",
    "    await asyncio.gather(count(), count(), count())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import time\n",
    "    s = time.perf_counter()\n",
    "    asyncio.run(main())\n",
    "    elapsed = time.perf_counter() - s\n",
    "    print(f\"{__file__} executed in {elapsed:0.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Script requires Python 3.7+.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-52fdb0c9e09f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Script requires Python 3.7+.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m     \u001b[0mhere\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Script requires Python 3.7+."
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import logging\n",
    "import re\n",
    "import sys\n",
    "from typing import IO\n",
    "import urllib.error\n",
    "import urllib.parse\n",
    "\n",
    "import aiofiles\n",
    "import aiohttp\n",
    "from aiohttp import ClientSession\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s %(levelname)s:%(name)s: %(message)s\",\n",
    "    level=logging.DEBUG,\n",
    "    datefmt=\"%H:%M:%S\",\n",
    "    stream=sys.stderr,\n",
    ")\n",
    "logger = logging.getLogger(\"areq\")\n",
    "logging.getLogger(\"chardet.charsetprober\").disabled = True\n",
    "\n",
    "HREF_RE = re.compile(r'href=\"(.*?)\"')\n",
    "\n",
    "async def fetch_html(url: str, session: ClientSession, **kwargs) -> str:\n",
    "    \"\"\"GET request wrapper to fetch page HTML.\n",
    "\n",
    "    kwargs are passed to `session.request()`.\n",
    "    \"\"\"\n",
    "\n",
    "    resp = await session.request(method=\"GET\", url=url, **kwargs)\n",
    "    resp.raise_for_status()\n",
    "    logger.info(\"Got response [%s] for URL: %s\", resp.status, url)\n",
    "    html = await resp.text()\n",
    "    return html\n",
    "\n",
    "async def parse(url: str, session: ClientSession, **kwargs) -> set:\n",
    "    \"\"\"Find HREFs in the HTML of `url`.\"\"\"\n",
    "    found = set()\n",
    "    try:\n",
    "        html = await fetch_html(url=url, session=session, **kwargs)\n",
    "    except (\n",
    "        aiohttp.ClientError,\n",
    "        aiohttp.http_exceptions.HttpProcessingError,\n",
    "    ) as e:\n",
    "        logger.error(\n",
    "            \"aiohttp exception for %s [%s]: %s\",\n",
    "            url,\n",
    "            getattr(e, \"status\", None),\n",
    "            getattr(e, \"message\", None),\n",
    "        )\n",
    "        return found\n",
    "    except Exception as e:\n",
    "        logger.exception(\n",
    "            \"Non-aiohttp exception occured:  %s\", getattr(e, \"__dict__\", {})\n",
    "        )\n",
    "        return found\n",
    "    else:\n",
    "        for link in HREF_RE.findall(html):\n",
    "            try:\n",
    "                abslink = urllib.parse.urljoin(url, link)\n",
    "            except (urllib.error.URLError, ValueError):\n",
    "                logger.exception(\"Error parsing URL: %s\", link)\n",
    "                pass\n",
    "            else:\n",
    "                found.add(abslink)\n",
    "        logger.info(\"Found %d links for %s\", len(found), url)\n",
    "        return found\n",
    "\n",
    "async def write_one(file: IO, url: str, **kwargs) -> None:\n",
    "    \"\"\"Write the found HREFs from `url` to `file`.\"\"\"\n",
    "    res = await parse(url=url, **kwargs)\n",
    "    if not res:\n",
    "        return None\n",
    "    async with aiofiles.open(file, \"a\") as f:\n",
    "        for p in res:\n",
    "            await f.write(f\"{url}\\t{p}\\n\")\n",
    "        logger.info(\"Wrote results for source URL: %s\", url)\n",
    "\n",
    "async def bulk_crawl_and_write(file: IO, urls: set, **kwargs) -> None:\n",
    "    \"\"\"Crawl & write concurrently to `file` for multiple `urls`.\"\"\"\n",
    "    async with ClientSession() as session:\n",
    "        tasks = []\n",
    "        for url in urls:\n",
    "            tasks.append(\n",
    "                write_one(file=file, url=url, session=session, **kwargs)\n",
    "            )\n",
    "        await asyncio.gather(*tasks)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import pathlib\n",
    "    import sys\n",
    "\n",
    "    assert sys.version_info >= (3, 7), \"Script requires Python 3.7+.\"\n",
    "    here = pathlib.Path(__file__).parent\n",
    "\n",
    "    with open(here.joinpath(\"urls.txt\")) as infile:\n",
    "        urls = set(map(str.strip, infile))\n",
    "\n",
    "    outpath = here.joinpath(\"foundurls.txt\")\n",
    "    with open(outpath, \"w\") as outfile:\n",
    "        outfile.write(\"source_url\\tparsed_url\\n\")\n",
    "\n",
    "    asyncio.run(bulk_crawl_and_write(file=outpath, urls=urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connecting to 10.17.35.208 port 102\n",
      "sending b'AAA'\n",
      "closing socket\n"
     ]
    },
    {
     "ename": "ConnectionResetError",
     "evalue": "[Errno 104] Connection reset by peer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionResetError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-df910ef2f408>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mamount_received\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mamount_expected\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mamount_received\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'received {!r}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionResetError\u001b[0m: [Errno 104] Connection reset by peer"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "\n",
    "# Create a TCP/IP socket\n",
    "sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "\n",
    "# Connect the socket to the port where the server is listening\n",
    "server_address = ('10.17.35.208', 102)\n",
    "print('connecting to {} port {}'.format(*server_address))\n",
    "sock.connect(server_address)\n",
    "try:\n",
    "\n",
    "    # Send data\n",
    "    message = b'AAA'\n",
    "    print('sending {!r}'.format(message))\n",
    "    sock.sendall(message)\n",
    "\n",
    "    # Look for the response\n",
    "    amount_received = 0\n",
    "    amount_expected = len(message)\n",
    "\n",
    "    while amount_received < amount_expected:\n",
    "        data = sock.recv(16)\n",
    "        amount_received += len(data)\n",
    "        print('received {!r}'.format(data))\n",
    "\n",
    "finally:\n",
    "    print('closing socket')\n",
    "    sock.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "This event loop is already running",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-84d05568f8cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mcoroutine_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhello\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Friends\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mcoroutine_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhello\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"World\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mIOLoop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tornado/platform/asyncio.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_logging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_event_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masyncio_loop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masyncio_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_forever\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_event_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_loop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/asyncio/base_events.py\u001b[0m in \u001b[0;36mrun_forever\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'This event loop is already running'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_running_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m             raise RuntimeError(\n",
      "\u001b[0;31mRuntimeError\u001b[0m: This event loop is already running"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, Friends!\tts: 1564757268.0310104\n",
      "Hello, Friends!\tts: 1564757269.0340078\n",
      "Hello, World!\tts: 1564757269.5276332\n",
      "Hello, Friends!\tts: 1564757270.0363925\n",
      "Hello, Friends!\tts: 1564757271.0368083\n",
      "Hello, World!\tts: 1564757272.0292673\n",
      "Hello, Friends!\tts: 1564757272.038219\n",
      "Hello, Friends!\tts: 1564757273.0387654\n",
      "Hello, Friends!\tts: 1564757274.039946\n",
      "Hello, World!\tts: 1564757274.5314252\n",
      "Hello, Friends!\tts: 1564757275.0411937\n",
      "Hello, Friends!\tts: 1564757276.0426445\n",
      "Hello, World!\tts: 1564757277.0330334\n",
      "Hello, Friends!\tts: 1564757277.0436606\n",
      "Hello, Friends!\tts: 1564757278.0455492\n",
      "Hello, Friends!\tts: 1564757279.046621\n",
      "Hello, World!\tts: 1564757279.5372212\n",
      "Hello, Friends!\tts: 1564757280.048112\n",
      "Hello, Friends!\tts: 1564757281.0493908\n",
      "Hello, World!\tts: 1564757282.0393655\n",
      "Hello, Friends!\tts: 1564757282.0517588\n",
      "Hello, Friends!\tts: 1564757283.05539\n",
      "Hello, Friends!\tts: 1564757284.0568929\n",
      "Hello, World!\tts: 1564757284.5428803\n",
      "Hello, Friends!\tts: 1564757285.058081\n",
      "Hello, Friends!\tts: 1564757286.0594862\n",
      "Hello, World!\tts: 1564757287.0464728\n",
      "Hello, Friends!\tts: 1564757287.0619702\n",
      "Hello, Friends!\tts: 1564757288.0635874\n",
      "Hello, Friends!\tts: 1564757289.064958\n",
      "Hello, World!\tts: 1564757289.5488598\n",
      "Hello, Friends!\tts: 1564757290.067896\n",
      "Hello, Friends!\tts: 1564757291.0702326\n",
      "Hello, World!\tts: 1564757292.0511224\n",
      "Hello, Friends!\tts: 1564757292.072056\n",
      "Hello, Friends!\tts: 1564757293.0757465\n",
      "Hello, Friends!\tts: 1564757294.0771866\n",
      "Hello, World!\tts: 1564757294.5584304\n",
      "Hello, Friends!\tts: 1564757295.0779898\n",
      "Hello, Friends!\tts: 1564757296.0803285\n",
      "Hello, World!\tts: 1564757297.0618045\n",
      "Hello, Friends!\tts: 1564757297.081345\n",
      "Hello, Friends!\tts: 1564757298.0822313\n",
      "Hello, Friends!\tts: 1564757299.0835028\n",
      "Hello, World!\tts: 1564757299.5645807\n",
      "Hello, Friends!\tts: 1564757300.0852504\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from collections import deque\n",
    "from tornado.ioloop import IOLoop\n",
    "\n",
    "current = deque()\n",
    "\n",
    "class sleep(object):\n",
    "\n",
    "    def __init__(self, timeout):\n",
    "        self.deadline = time() + timeout\n",
    "\n",
    "    def __await__(self):\n",
    "        def swith_to(coro):\n",
    "            current.append(coro)\n",
    "            coro.send(time())\n",
    "        IOLoop.instance().add_timeout(self.deadline, swith_to, current[0])\n",
    "        current.pop()\n",
    "        return (yield)\n",
    "\n",
    "def coroutine_start(run, *args, **kwargs):\n",
    "    coro = run(*args, **kwargs)\n",
    "    current.append(coro)\n",
    "    coro.send(None)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    async def hello(name, timeout):\n",
    "        while True:\n",
    "            now = await sleep(timeout)\n",
    "            print(\"Hello, {}!\\tts: {}\".format(name, now))\n",
    "\n",
    "    coroutine_start(hello, \"Friends\", 1.0)\n",
    "    coroutine_start(hello, \"World\", 2.5)\n",
    "    IOLoop.instance().start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The name of continent is :  Europe\n",
      "The name of continent is :  Africa\n",
      "The name of continent is :  Asia\n",
      "The name of continent is :  America\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process\n",
    "\n",
    "\n",
    "def print_func(continent='Asia'):\n",
    "    print('The name of continent is : ', continent)\n",
    "\n",
    "if __name__ == \"__main__\":  # confirms that the code is under main function\n",
    "    names = ['America', 'Europe', 'Africa']\n",
    "    procs = []\n",
    "    proc = Process(target=print_func)  # instantiating without any argument\n",
    "    procs.append(proc)\n",
    "    proc.start()\n",
    "\n",
    "    # instantiating process with arguments\n",
    "    for name in names:\n",
    "        # print(name)\n",
    "        proc = Process(target=print_func, args=(name,))\n",
    "        procs.append(proc)\n",
    "        proc.start()\n",
    "\n",
    "    # complete the processes\n",
    "    for proc in procs:\n",
    "        proc.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Square: 100\n",
      "Cube: 1000\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    " \n",
    "def print_cube(num):\n",
    "    \"\"\"\n",
    "    function to print cube of given num\n",
    "    \"\"\"\n",
    "    print(\"Cube: {}\".format(num * num * num))\n",
    "    \n",
    "def print_square(num):\n",
    "    \"\"\"\n",
    "    function to print square of given num\n",
    "    \"\"\"\n",
    "    print(\"Square: {}\".format(num * num))\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    # creating thread\n",
    "    t1 = threading.Thread(target=print_square, args=(10,))\n",
    "    t2 = threading.Thread(target=print_cube, args=(10,))\n",
    " \n",
    "    # starting thread 1\n",
    "    t1.start()\n",
    "    # starting thread 2\n",
    "    t2.start()\n",
    " \n",
    "    # wait until thread 1 is completely executed\n",
    "    t1.join()\n",
    "    # wait until thread 2 is completely executed\n",
    "    t2.join()\n",
    " \n",
    "    # both threads completely executed\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching prefix:Dear\n",
      "Dear James\n",
      "Dear Carl\n",
      "Closing coroutine!!\n"
     ]
    }
   ],
   "source": [
    "def print_name(prefix):\n",
    "    print(\"Searching prefix:{}\".format(prefix))\n",
    "    try : \n",
    "        while True:\n",
    "                # yeild used to create coroutine\n",
    "                name = (yield)\n",
    "                if prefix in name:\n",
    "                    print(name)\n",
    "    except GeneratorExit:\n",
    "            print(\"Closing coroutine!!\")\n",
    "\n",
    "corou = print_name(\"Dear\")\n",
    "corou.__next__()\n",
    "corou.send(\"James\")\n",
    "corou.send(\"Dear James\")\n",
    "corou.send(\"Dear Carl\")\n",
    "corou.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "This event loop is already running",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ed5e3d239260>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_future\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_reddit_top\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'programming'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_future\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_reddit_top\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'compsci'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_forever\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3.6/asyncio/base_events.py\u001b[0m in \u001b[0;36mrun_forever\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'This event loop is already running'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_running_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m             raise RuntimeError(\n",
      "\u001b[0;31mRuntimeError\u001b[0m: This event loop is already running"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "861: Had open-sourced a small script I wrote and mostly forgot about it. But then this happened and made my day!!! (https://i.redd.it/vy83cl7grud31.png)\n",
      "738: So i turned old processor into keychain. What do you guys think about it? (https://i.redd.it/fvypokfoyzd31.jpg)\n",
      "310: How I saved &gt;1000 years of CPU time using my adaptive sampling package for this quantum mechanics plot [OC] (https://v.redd.it/c5ygo9c030e31)\n",
      "10: Free mentoring in python and other languages (https://www.reddit.com/r/Python/comments/cl1t2i/free_mentoring_in_python_and_other_languages/)\n",
      "3: Async Python is used in production. This is how. (https://youtu.be/pIXiChn5j4E)\n",
      "DONE: python\n",
      "\n",
      "1056: The Technical Side of the Capital One AWS Security Breach (https://start.jcolemorrison.com/the-technical-side-of-the-capital-one-aws-security-breach/)\n",
      "78: Readable Specification of TLS 1.3 (https://davidwong.fr/tls13/)\n",
      "59: Typed properties in PHP 7.4 (https://stitcher.io/blog/typed-properties-in-php-74)\n",
      "27: MaybeUninit, the new(ly stabilized) way to work with uninitialized memory in Rust (https://gankro.github.io/blah/initialize-me-maybe/)\n",
      "22: Awesome article about how Riot has revolutionized their patching process! (https://technology.riotgames.com/news/supercharging-data-delivery-new-league-patcher)\n",
      "DONE: programming\n",
      "\n",
      "69: What Color is Your Function? (https://journal.stuffwithstuff.com/2015/02/01/what-color-is-your-function/)\n",
      "59: ACL 2019 | Best Papers Announced (https://medium.com/syncedreview/acl-2019-best-papers-announced-e0141024a935)\n",
      "10: CompSci Weekend SuperThread (August 02, 2019) (https://www.reddit.com/r/compsci/comments/ckx6oq/compsci_weekend_superthread_august_02_2019/)\n",
      "10: What is the appeal of weakly and dynamically typed languages? (https://www.reddit.com/r/compsci/comments/ckw9es/what_is_the_appeal_of_weakly_and_dynamically/)\n",
      "1: CFG for PDF specification? (https://www.reddit.com/r/compsci/comments/ckta03/cfg_for_pdf_specification/)\n",
      "DONE: compsci\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import signal  \n",
    "import sys  \n",
    "import asyncio  \n",
    "import aiohttp  \n",
    "import json\n",
    "\n",
    "loop = asyncio.get_event_loop()  \n",
    "client = aiohttp.ClientSession(loop=loop)\n",
    "\n",
    "async def get_json(client, url):  \n",
    "    async with client.get(url) as response:\n",
    "        assert response.status == 200\n",
    "        return await response.read()\n",
    "\n",
    "async def get_reddit_top(subreddit, client):  \n",
    "    data1 = await get_json(client, 'https://www.reddit.com/r/' + subreddit + '/top.json?sort=top&t=day&limit=5')\n",
    "\n",
    "    j = json.loads(data1.decode('utf-8'))\n",
    "    for i in j['data']['children']:\n",
    "        score = i['data']['score']\n",
    "        title = i['data']['title']\n",
    "        link = i['data']['url']\n",
    "        print(str(score) + ': ' + title + ' (' + link + ')')\n",
    "\n",
    "    print('DONE:', subreddit + '\\n')\n",
    "\n",
    "def signal_handler(signal, frame):  \n",
    "    loop.stop()\n",
    "    client.close()\n",
    "    sys.exit(0)\n",
    "\n",
    "signal.signal(signal.SIGINT, signal_handler)\n",
    "\n",
    "asyncio.ensure_future(get_reddit_top('python', client))  \n",
    "asyncio.ensure_future(get_reddit_top('programming', client))  \n",
    "asyncio.ensure_future(get_reddit_top('compsci', client))  \n",
    "loop.run_forever()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
