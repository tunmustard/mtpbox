{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import face_recognition\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "\n",
    "import time\n",
    "import threading\n",
    "try:\n",
    "    from greenlet import getcurrent as get_ident\n",
    "except ImportError:\n",
    "    try:\n",
    "        from thread import get_ident\n",
    "    except ImportError:\n",
    "        from _thread import get_ident\n",
    "\n",
    "\n",
    "class CameraEvent(object):\n",
    "    \"\"\"An Event-like class that signals all active clients when a new frame is\n",
    "    available.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.events = {}\n",
    "\n",
    "    def wait(self):\n",
    "        \"\"\"Invoked from each client's thread to wait for the next frame.\"\"\"\n",
    "        ident = get_ident()\n",
    "        if ident not in self.events:\n",
    "            # this is a new client\n",
    "            # add an entry for it in the self.events dict\n",
    "            # each entry has two elements, a threading.Event() and a timestamp\n",
    "            self.events[ident] = [threading.Event(), time.time()]\n",
    "        return self.events[ident][0].wait()\n",
    "\n",
    "    def set(self):\n",
    "        \"\"\"Invoked by the camera thread when a new frame is available.\"\"\"\n",
    "        now = time.time()\n",
    "        remove = None\n",
    "        for ident, event in self.events.items():\n",
    "            if not event[0].isSet():\n",
    "                # if this client's event is not set, then set it\n",
    "                # also update the last set timestamp to now\n",
    "                event[0].set()\n",
    "                event[1] = now\n",
    "            else:\n",
    "                # if the client's event is already set, it means the client\n",
    "                # did not process a previous frame\n",
    "                # if the event stays set for more than 5 seconds, then assume\n",
    "                # the client is gone and remove it\n",
    "                if now - event[1] > 5:\n",
    "                    remove = ident\n",
    "        if remove:\n",
    "            del self.events[remove]\n",
    "\n",
    "    def clear(self):\n",
    "        \"\"\"Invoked from each client's thread after a frame was processed.\"\"\"\n",
    "        self.events[get_ident()][0].clear()\n",
    "\n",
    "\n",
    "class BaseCamera(object):\n",
    "    thread = None  # background thread that reads frames from camera\n",
    "    frame = None  # current frame is stored here by background thread\n",
    "    last_access = 0  # time of last client access to the camera\n",
    "    event = CameraEvent()\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Start the background camera thread if it isn't running yet.\"\"\"\n",
    "        if BaseCamera.thread is None:\n",
    "            BaseCamera.last_access = time.time()\n",
    "\n",
    "            # start background frame thread\n",
    "            BaseCamera.thread = threading.Thread(target=self._thread)\n",
    "            BaseCamera.thread.start()\n",
    "\n",
    "            # wait until frames are available\n",
    "            while self.get_frame() is None:\n",
    "                time.sleep(0)\n",
    "\n",
    "    def get_frame(self):\n",
    "        \"\"\"Return the current camera frame.\"\"\"\n",
    "        BaseCamera.last_access = time.time()\n",
    "\n",
    "        # wait for a signal from the camera thread\n",
    "        BaseCamera.event.wait()\n",
    "        BaseCamera.event.clear()\n",
    "\n",
    "        return BaseCamera.frame\n",
    "\n",
    "    @staticmethod\n",
    "    def frames():\n",
    "        \"\"\"\"Generator that returns frames from the camera.\"\"\"\n",
    "        raise RuntimeError('Must be implemented by subclasses.')\n",
    "\n",
    "    @classmethod\n",
    "    def _thread(cls):\n",
    "        \"\"\"Camera background thread.\"\"\"\n",
    "        print('Starting camera thread.')\n",
    "        frames_iterator = cls.frames()\n",
    "        for frame in frames_iterator:\n",
    "            BaseCamera.frame = frame\n",
    "            BaseCamera.event.set()  # send signal to clients\n",
    "            time.sleep(0)\n",
    "\n",
    "            # if there hasn't been any clients asking for frames in\n",
    "            # the last 10 seconds then stop the thread\n",
    "            if time.time() - BaseCamera.last_access > 10:\n",
    "                frames_iterator.close()\n",
    "                print('Stopping camera thread due to inactivity.')\n",
    "                break\n",
    "        BaseCamera.thread = None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Camera_compare(BaseCamera):\n",
    "    video_source = 0\n",
    "    path_core_img = \"./static/idimage/\"\n",
    "    path_core_csv = \"./core_export.csv\" #coreexport\n",
    "    path_dict_csv = './dict.csv'\n",
    "    img_format=\".jpg\"\n",
    "    last_encoding = []\n",
    "    encodings_core = {}\n",
    "    encodings_few = {}\n",
    "    enc_reset_cnt = 0\n",
    "    enc_reset_cnt_lim = 20\n",
    "    enc_add_to_core_cnt_lim = 8\n",
    "    few_id_cnt = 0\n",
    "    name_dict = {}\n",
    "    \n",
    "    def get_names_dict(file_name):\n",
    "        try:\n",
    "            with open(file_name, mode='r') as infile:\n",
    "                reader = csv.reader(infile)\n",
    "                #structure 0-ID 1-Name\n",
    "                next(reader, None) \n",
    "                name_dict = {int(rows[0]):rows[1] for rows in reader}\n",
    "                print(\"dictionary: \",name_dict)\n",
    "        except EnvironmentError: # parent of IOError, OSError *and* WindowsError where available\n",
    "            print(\"--No dictionary file--\")\n",
    "            name_dict = {}   \n",
    "        return name_dict\n",
    "\n",
    "    #some logic to update user names dict\n",
    "    def update_name_dict(filename):\n",
    "        if Camera_compare.enc_reset_cnt == 0:\n",
    "            Camera_compare.name_dict = Camera_compare.get_names_dict(filename)\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def set_video_source(source):\n",
    "        Camera_compare.video_source = source\n",
    "\n",
    "    def get_id_name(key):\n",
    "        try:\n",
    "            name = Camera_compare.name_dict[key]\n",
    "        except KeyError:\n",
    "            name = str(key)\n",
    "        return name\n",
    "    \n",
    "    def get_name(encoding):\n",
    "        name = \"Undefined\"\n",
    "        found_likeness=0\n",
    "        if bool(Camera_compare.encodings_core):\n",
    "            for key, value in Camera_compare.encodings_core.items():\n",
    "                if any(face_recognition.compare_faces(value, encoding, tolerance = 0.5)):\n",
    "                    try:\n",
    "                        name = Camera_compare.name_dict[key]\n",
    "                        print(\"Found likeness in core key, from dictionary ID %s = %s\"%(str(key),name))\n",
    "                    except KeyError:\n",
    "                        name = str(key)\n",
    "                        print(\"Found likeness in core, ID %s\"%name)\n",
    "                    found_likeness = 1\n",
    "                    break\n",
    "        if not found_likeness:\n",
    "            print(\"No likeness found in core, name = %s\"%name)\n",
    "        return name     \n",
    "\n",
    "    def add_to_core(encodings):\n",
    "        #next key\n",
    "        num = len(Camera_compare.encodings_core)\n",
    "        exist_in_core = 0\n",
    "        \n",
    "        #transform incoming encodings --> averaging\n",
    "        encoding = np.average(encodings,axis = 0)\n",
    "        if bool(Camera_compare.encodings_core):\n",
    "            for key, value in Camera_compare.encodings_core.items():\n",
    "                if any(face_recognition.compare_faces(value, encoding, tolerance = 0.5)):\n",
    "                    #encoding already exist in core\n",
    "                    exist_in_core = exist_in_core + 1\n",
    "                    break\n",
    "        \n",
    "        if exist_in_core==0:\n",
    "            ##add new encoding to core\n",
    "            Camera_compare.encodings_core[num] = [encoding]    \n",
    "            print(\"Adding to core with id = %s\"%num)\n",
    "            return num\n",
    "        else:\n",
    "            print(\"Id already exist in core\")\n",
    "            return None\n",
    "             \n",
    "\n",
    "    def reset_few():\n",
    "        #reset few buffer\n",
    "        Camera_compare.enc_reset_cnt+=1\n",
    "        if Camera_compare.enc_reset_cnt >= Camera_compare.enc_reset_cnt_lim:\n",
    "            Camera_compare.encodings_few = {}\n",
    "            Camera_compare.enc_reset_cnt = 0\n",
    "            Camera_compare.few_id_cnt = 0\n",
    "            Camera_compare.core_export(Camera_compare.encodings_core)\n",
    "            print(\"reset counter reached, clearing encodings_few\")\n",
    "        \n",
    "    \n",
    "    def print_few_struct():\n",
    "        #Printout\n",
    "        printout_text = \"Encoding few structure: \\n\"\n",
    "        if len(Camera_compare.encodings_few):\n",
    "            for key, value in Camera_compare.encodings_few.items():\n",
    "                printout_text = \"%s node '%s', length %s;  \\n\"%(printout_text,key,len(Camera_compare.encodings_few[key]))\n",
    "        else:\n",
    "            printout_text = \"%s -- none --\"%printout_text   \n",
    "        print(printout_text) \n",
    "\n",
    "    def add_to_img(new_id,crop_img,save_path=path_core_img,save_format=img_format):\n",
    "        return cv2.imwrite(''.join((save_path,str(new_id),save_format)),crop_img)        \n",
    "\n",
    "    def core_export(core,filename=path_core_csv):\n",
    "        a = [[key, ','.join(str(e) for e in value[0]) ] for key,value in core.items()]\n",
    "        with open(filename, 'w', newline='') as csvfile:\n",
    "            csvwriter = csv.writer(csvfile, delimiter=';')\n",
    "            csvwriter.writerow(['ID', 'encoding'])\n",
    "            for k in a:\n",
    "                csvwriter.writerow([k[0], k[1]])\n",
    "            print(\"<<--core has been exported-->>\")\n",
    "\n",
    "    def core_import(filename=path_core_csv):   \n",
    "        try:\n",
    "            with open(filename, mode='r') as csvfile:\n",
    "                reader = csv.reader(csvfile,delimiter=';')\n",
    "                #structure 0-ID 1-eocodings\n",
    "                next(reader, None) \n",
    "                core_imported = {int(rows[0]):[[float(x) for x in rows[1].split(',')]] for rows in reader}\n",
    "                print(\"<<--core has been imported-->>\")\n",
    "        except EnvironmentError: # parent of IOError, OSError *and* WindowsError where available\n",
    "            print(\"--No core import file--\")\n",
    "            core_imported = {}\n",
    "        return core_imported\n",
    "    \n",
    "    def add_to_few(encoding,rgb_frame,top, right, bottom, left):\n",
    "\n",
    "        if bool(Camera_compare.encodings_few):\n",
    "            likehood_counter = 0\n",
    "            merge_dict = {}\n",
    "            full_dict = {}\n",
    "\n",
    "            #Camera_compare.print_few_struct()\n",
    "            for key, value in Camera_compare.encodings_few.items():\n",
    "                #check maximum numbers of likeness encoding for each ID\n",
    "                if len(value)>=Camera_compare.enc_add_to_core_cnt_lim:\n",
    "                    full_dict[len(full_dict)]=key\n",
    "                    continue\n",
    "                #check encodings few base\n",
    "                if any(face_recognition.compare_faces(value, encoding, tolerance = 0.3)):\n",
    "                    if likehood_counter > 0:\n",
    "                        merge_dict[merge_num_0]=key\n",
    "                    else:\n",
    "                        print(\"Appending likeness to encodings_few node '%s'\"%(key))\n",
    "                        #do not add to merging nodes\n",
    "                        Camera_compare.encodings_few[key].append(encoding)\n",
    "                        merge_num_0 = key\n",
    "                    likehood_counter += 1\n",
    "\n",
    "            #adding new likeness node to few base\n",
    "            if likehood_counter == 0:\n",
    "                Camera_compare.encodings_few[Camera_compare.few_id_cnt]=[encoding] \n",
    "                print(\"No likeness found in few, creating new node %s\"%Camera_compare.few_id_cnt)\n",
    "                Camera_compare.few_id_cnt += 1\n",
    "   \n",
    "            #merging two likeness nodes\n",
    "            if bool(merge_dict):\n",
    "                print(\"Similar nodes found, merging dict is: %s\"%merge_dict)\n",
    "                for key, value in merge_dict.items():\n",
    "                    Camera_compare.encodings_few[key].extend(Camera_compare.encodings_few.pop(value))\n",
    "      \n",
    "            #add full node to core\n",
    "            if bool(full_dict):\n",
    "                for key, value in full_dict.items():\n",
    "                    print(\"few node %s is full\"%value)\n",
    "                    new_id = Camera_compare.add_to_core(Camera_compare.encodings_few[value])\n",
    "                    #add to image base if have added to core successfully\n",
    "                    if new_id is not None:\n",
    "                        Camera_compare.add_to_img(new_id,rgb_frame[top:bottom,left:right])\n",
    "                    Camera_compare.encodings_few.pop(value) \n",
    "            \n",
    "            Camera_compare.print_few_struct()\n",
    "           \n",
    "        \n",
    "        else:\n",
    "            print(\"Encodings_few is empty, adding first node\")\n",
    "            Camera_compare.encodings_few[len(Camera_compare.encodings_few)]=[encoding]\n",
    "                \n",
    "    @staticmethod\n",
    "    def frames():\n",
    "        camera = cv2.VideoCapture(Camera_compare.video_source)\n",
    "        if not camera.isOpened():\n",
    "            raise RuntimeError('Could not start camera.')\n",
    "        \n",
    "        #core_import\n",
    "        Camera_compare.encodings_core = Camera_compare.core_import()\n",
    "        \n",
    "        while True:\n",
    "            # read current frame\n",
    "            _, frame = camera.read()\n",
    "\n",
    "            # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n",
    "            rgb_frame = frame[:, :, ::-1]\n",
    "\n",
    "            # Find all the faces and face enqcodings in the frame of video\n",
    "            face_locations = face_recognition.face_locations(rgb_frame)\n",
    "            face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "            # Loop through each face in this frame of video\n",
    "            face_iter = 0\n",
    "            for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "                \n",
    "                print(\"--------------->\")\n",
    "                \n",
    "                #udate name dictionary\n",
    "                Camera_compare.update_name_dict(Camera_compare.path_dict_csv)\n",
    "                \n",
    "                #clear few buffer time to time\n",
    "                Camera_compare.reset_few()\n",
    "                \n",
    "                #check new encoding\n",
    "                Camera_compare.add_to_few(face_encoding,rgb_frame,top, right, bottom, left)\n",
    "                \n",
    "                # See if the face is a match for the known face(s)\n",
    "                name = Camera_compare.get_name(face_encoding)\n",
    "                face_iter += 1\n",
    "  \n",
    "                # Draw a box around the face\n",
    "                cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "                \n",
    "            \n",
    "            \n",
    "                # Draw a label with a name below the face\n",
    "                cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "                font = cv2.FONT_HERSHEY_DUPLEX\n",
    "                cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "                \n",
    "            #for face_landmarks in face_landmarks_list:\n",
    "            #    pil_image = Image.fromarray(frame)\n",
    "            #    d = ImageDraw.Draw(pil_image, 'RGBA')\n",
    "            #    # Make the eyebrows into a nightmare\n",
    "            #    print(face_landmarks['left_eyebrow'])\n",
    "            #    d.polygon(face_landmarks['left_eyebrow'], fill=(68, 54, 39, 128))\n",
    "            #    d.polygon(face_landmarks['right_eyebrow'], fill=(68, 54, 39, 128))\n",
    "            #    frame = numpy.array(pil_image.getdata(),\n",
    "            #        numpy.uint8).reshape(pil_image.size[1], pil_image.size[0], 3)\n",
    "            # encode as a jpeg image and return it\n",
    "            #yield cv2.imencode('.jpg', frame)[1].tobytes()\n",
    "            yield frame\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Camera_compare' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a6227a8ccc8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCamera_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#cv2.imwrite('../data/out/%s.png'%i,frame)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Camera_compare' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "cam = Camera_compare()\n",
    "for i in range(50):\n",
    "    frame = cam.get_frame()\n",
    "    #cv2.imwrite('../data/out/%s.png'%i,frame)\n",
    "    #time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-7da5098a1b71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"obama-720p.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mleft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def add_to_img(new_id,crop_img):\n",
    "    save_path = \"./ids/\"\n",
    "    save_prefix = \"\"\n",
    "    save_format = \".jpg\"\n",
    "    return cv2.imwrite(''.join((save_path,save_prefix,str(new_id),save_format)),crop_img)\n",
    "\n",
    "img = cv2.imread(\"obama-720p.jpg\")\n",
    "img = img[:,:,::-1]\n",
    "left = 100\n",
    "right = 400\n",
    "top = 100\n",
    "bottom = 800\n",
    "crop_img = img[left:right, top:bottom]\n",
    "add_to_img(1,crop_img)\n",
    "\n",
    "#plt.imshow(crop_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Could not start camera.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-0b4a06f6fade>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcamera\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcamera\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misOpened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Could not start camera.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Could not start camera."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "camera = cv2.VideoCapture(0)\n",
    "if not camera.isOpened():\n",
    "    raise RuntimeError('Could not start camera.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
